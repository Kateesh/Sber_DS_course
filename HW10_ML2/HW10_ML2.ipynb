{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_boston()\n",
    "X = pd.DataFrame(dataset.data)\n",
    "X.columns = dataset.feature_names\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Разделите выборку на обучающую и тестовую в отношении 80%/20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (102, 13), (404,), (102,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Обучите стандартную регрессию, а также Ridge и  Lasso и параметрами по умолчанию и выведите их R2 на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.669\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.666\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "print (f'R2: {ridge.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.667\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "lasso.fit(X_train, y_train)\n",
    "print (f'R2: {lasso.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Для Ridge и Lasso подберите коэффициент регуляризации(используйте GridSearchCV, RidgeCV, LassoCV) в пределах от $10^{-5}$ до $10^5$ (по степеням 10). Посчитайте R2 на тестовой выборке по лучшим моделям и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "powers = []\n",
    "for i in range(-5, 6):\n",
    "    power = 10**(i)\n",
    "    powers.append(power)\n",
    "\n",
    "powers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=1e-05)\n",
      "R2: 0.669\n"
     ]
    }
   ],
   "source": [
    "parameters = {'alpha': powers}\n",
    "\n",
    "model = Ridge()\n",
    "Ridge_reg= GridSearchCV(model, parameters, scoring='r2', cv=10)\n",
    "Ridge_reg.fit(X_train, y_train)\n",
    "print(Ridge_reg.best_estimator_)\n",
    "\n",
    "best_model = Ridge_reg.best_estimator_\n",
    "best_model.fit(X_train,y_train)\n",
    "\n",
    "print (f'R2: {best_model.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.669\n"
     ]
    }
   ],
   "source": [
    "ridgeCV = RidgeCV(alphas = powers)\n",
    "ridgeCV.fit(X_train, y_train)\n",
    "print (f'R2: {ridgeCV.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# результат через RidgeCV и GridsearchCV получается одинаковый\n",
    "# результат немного лучше, чем для модели без регуляризации "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso(alpha=1e-05)\n",
      "R2: 0.669\n"
     ]
    }
   ],
   "source": [
    "parameters = {'alpha': powers}\n",
    "\n",
    "model = Lasso()\n",
    "Lasso_reg= GridSearchCV(model, parameters, scoring='r2', cv=10)\n",
    "Lasso_reg.fit(X_train, y_train)\n",
    "print(Lasso_reg.best_estimator_)\n",
    "\n",
    "best_model = Lasso_reg.best_estimator_\n",
    "best_model.fit(X_train,y_train)\n",
    "\n",
    "print (f'R2: {best_model.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.669\n"
     ]
    }
   ],
   "source": [
    "model = LassoCV(alphas = powers)\n",
    "model.fit(X_train, y_train)\n",
    "print (f'R2: {model.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# результат через LassoCV и GridsearchCV получается одинаковый\n",
    "# результат немного лучше, чем для модели без регуляризации "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Проведите масштабирование выборки(используйте Pipeline, StandardScaler, MinMaxScaler), посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_pipeline = Pipeline(steps=[\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "minmax_pipeline = Pipeline(steps=[\n",
    "    ('scale', MinMaxScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard_Scaler\n",
    "\n",
    "lr = LinearRegression()\n",
    "lasso = Lasso()\n",
    "ridge = Ridge()\n",
    "\n",
    "lr_pipeline_s = Pipeline(steps=[\n",
    "    ('preprocess', standard_pipeline),\n",
    "    ('model', lr)\n",
    "])\n",
    "\n",
    "lasso_pipeline_s = Pipeline(steps=[\n",
    "    ('preprocess', standard_pipeline),\n",
    "    ('model', lasso)\n",
    "])\n",
    "\n",
    "ridge_pipeline_s = Pipeline(steps=[\n",
    "    ('preprocess', standard_pipeline),\n",
    "    ('model', ridge)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax_Scaler\n",
    "\n",
    "lr_pipeline_m = Pipeline(steps=[\n",
    "    ('preprocess', minmax_pipeline),\n",
    "    ('model', lr)\n",
    "])\n",
    "\n",
    "lasso_pipeline_m = Pipeline(steps=[\n",
    "    ('preprocess', minmax_pipeline),\n",
    "    ('model', lasso)\n",
    "])\n",
    "\n",
    "ridge_pipeline_m = Pipeline(steps=[\n",
    "    ('preprocess', minmax_pipeline),\n",
    "    ('model', ridge)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Scaler\n",
      "Linear R2: 0.669\n",
      "Lasso R2: 0.624\n",
      "Ridge R2: 0.668\n"
     ]
    }
   ],
   "source": [
    "lr_pipeline_s.fit(X_train, y_train)\n",
    "lasso_pipeline_s.fit(X_train, y_train)\n",
    "ridge_pipeline_s.fit(X_train, y_train)\n",
    "\n",
    "y_pred_s = lr_pipeline_s.predict(X_test)\n",
    "r2_s = r2_score(y_test, y_pred_s)\n",
    "\n",
    "print('Standard Scaler')\n",
    "print(f'Linear R2: {r2_s:.3f}')\n",
    "print (f'Lasso R2: {lasso_pipeline_s.score(X_test, y_test):.3f}')\n",
    "print (f'Ridge R2: {ridge_pipeline_s.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# использование Standard_Scaler не повлияло на линейную модель, результаты Lasso и Ridge ухудшились"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minmax Scaler\n",
      "Linear R2: 0.669\n",
      "Lasso R2: 0.257\n",
      "Ridge R2: 0.676\n"
     ]
    }
   ],
   "source": [
    "lr_pipeline_m.fit(X_train, y_train)\n",
    "lasso_pipeline_m.fit(X_train, y_train)\n",
    "ridge_pipeline_m.fit(X_train, y_train)\n",
    "\n",
    "y_pred_m = lr_pipeline_m.predict(X_test)\n",
    "r2_m = r2_score(y_test, y_pred_m)\n",
    "\n",
    "print('Minmax Scaler')\n",
    "print(f'Linear R2: {r2_m:.3f}')\n",
    "print (f'Lasso R2: {lasso_pipeline_m.score(X_test, y_test):.3f}')\n",
    "print (f'Ridge R2: {ridge_pipeline_m.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# использование MinMax_Scaler не повлияло на линейную модель, результаты Lasso и Ridge ухудшились (Lasso - значительно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge - best alpha: 1\n",
      "R2: 0.676\n"
     ]
    }
   ],
   "source": [
    "parameters = {'alpha': powers}\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', 'passthrough'),\n",
    "    ('model', 'passthrough')\n",
    "])\n",
    "\n",
    "parameters = [{\n",
    "    'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "    'model': [Ridge()],\n",
    "    'model__alpha': powers\n",
    "}]\n",
    "\n",
    "Ridge_reg= GridSearchCV(pipe, parameters, scoring='r2', cv=10, n_jobs = -1)\n",
    "Ridge_reg.fit(X_train, y_train)\n",
    "\n",
    "print('Ridge - best alpha:', Ridge_reg.best_params_['model__alpha'])\n",
    "\n",
    "best_model = Ridge_reg.best_estimator_\n",
    "best_model.fit(X_train,y_train)\n",
    "\n",
    "print (f'R2: {best_model.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подбор параметров для Ridge позволил улучшить результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso - best alpha: 0.01\n",
      "R2: 0.668\n"
     ]
    }
   ],
   "source": [
    "parameters = {'alpha': powers}\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', 'passthrough'),\n",
    "    ('model', 'passthrough')\n",
    "])\n",
    "\n",
    "parameters = [{\n",
    "    'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "    'model': [Lasso()],\n",
    "    'model__alpha': powers\n",
    "}]\n",
    "\n",
    "Lasso_reg= GridSearchCV(pipe, parameters, scoring='r2', cv=10, n_jobs = -1)\n",
    "Lasso_reg.fit(X_train, y_train)\n",
    "\n",
    "print('Lasso - best alpha:', Lasso_reg.best_params_['model__alpha'])\n",
    "\n",
    "best_model = Lasso_reg.best_estimator_\n",
    "best_model.fit(X_train,y_train)\n",
    "\n",
    "print (f'R2: {best_model.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подбор параметров для Lasso дает результат, сопоставимый с линейной регрессией"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Добавьте попарные произведения признаков и их квадраты (используйте PolynomialFeatures) на масштабированных признаках, посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_pipeline_s = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('preprocessor', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "])\n",
    "\n",
    "poly_pipeline_m = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('preprocessor', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline_poly_s = Pipeline(steps=[\n",
    "    ('preprocess', poly_pipeline_s),\n",
    "    ('model',lr)\n",
    "])\n",
    "\n",
    "lasso_pipeline_poly_s = Pipeline(steps=[\n",
    "    ('preprocess', poly_pipeline_s),\n",
    "    ('model',lasso)\n",
    "])\n",
    "\n",
    "ridge_pipeline_poly_s = Pipeline(steps=[\n",
    "    ('preprocess', poly_pipeline_s),\n",
    "    ('model', ridge)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline_poly_m = Pipeline(steps=[\n",
    "    ('preprocess', poly_pipeline_m),\n",
    "    ('model',lr)\n",
    "])\n",
    "\n",
    "lasso_pipeline_poly_m = Pipeline(steps=[\n",
    "    ('preprocess', poly_pipeline_m),\n",
    "    ('model',lasso)\n",
    "])\n",
    "\n",
    "ridge_pipeline_poly_m = Pipeline(steps=[\n",
    "    ('preprocess', poly_pipeline_m),\n",
    "    ('model', ridge)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial features, Standard Scaler\n",
      "Linear R2: 0.805\n",
      "Lasso R2: 0.732\n",
      "Ridge R2: 0.816\n"
     ]
    }
   ],
   "source": [
    "lr_pipeline_poly_s.fit(X_train, y_train)\n",
    "lasso_pipeline_poly_s.fit(X_train, y_train)\n",
    "ridge_pipeline_poly_s.fit(X_train, y_train)\n",
    "\n",
    "y_pred_poly_s = lr_pipeline_poly_s.predict(X_test)\n",
    "r2_poly_s = r2_score(y_test, y_pred_poly_s)\n",
    "\n",
    "print('Polynomial features, Standard Scaler')\n",
    "print(f'Linear R2: {r2_poly_s:.3f}')\n",
    "print (f'Lasso R2: {lasso_pipeline_poly_s.score(X_test, y_test):.3f}')\n",
    "print (f'Ridge R2: {ridge_pipeline_poly_s.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# использование полиномиальных фич и Standard_Scaler позволяет улучшить результат по всем видам моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial features, MinMax Scaler\n",
      "Linear R2: 0.806\n",
      "Lasso R2: 0.261\n",
      "Ridge R2: 0.830\n"
     ]
    }
   ],
   "source": [
    "lr_pipeline_poly_m.fit(X_train, y_train)\n",
    "lasso_pipeline_poly_m.fit(X_train, y_train)\n",
    "ridge_pipeline_poly_m.fit(X_train, y_train)\n",
    "\n",
    "y_pred_poly_m = lr_pipeline_poly_m.predict(X_test)\n",
    "r2_poly_m = r2_score(y_test, y_pred_poly_m)\n",
    "\n",
    "print('Polynomial features, MinMax Scaler')\n",
    "print(f'Linear R2: {r2_poly_m:.3f}')\n",
    "print (f'Lasso R2: {lasso_pipeline_poly_m.score(X_test, y_test):.3f}')\n",
    "print (f'Ridge R2: {ridge_pipeline_poly_m.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# использование полиномиальных фич и MinMax_Scaler позволяет улучшить результат по линейной модели и Ridge\n",
    "# результат для Lasso значительно ниже baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Подберите наилучшую модель (используйте Pipeline, GridSearchSCV) подбирая тип регуляризации (L1,L2), коэффициент регуляризации, метод масштабирования и степень полинома в PolynomialFeatures. Выведите итоговые параметры и результат R2. Напишите как изменился R2 по сравнению с предыдущими экспериментами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('scaler', 'passthrough'),\n",
       "                                       ('preprocess', 'passthrough'),\n",
       "                                       ('model', 'passthrough')]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'model': [Ridge(alpha=0.1), Lasso()],\n",
       "                          'model__alpha': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1,\n",
       "                                           10, 100, 1000, 10000, 100000],\n",
       "                          'preprocess': [None,\n",
       "                                         PolynomialFeatures(include_bias=False),\n",
       "                                         PolynomialFeatures(degree=3,\n",
       "                                                            include_bias=False),\n",
       "                                         PolynomialFeatures(degree=4,\n",
       "                                                            include_bias=False)],\n",
       "                          'scaler': [None, StandardScaler(), MinMaxScaler()]}],\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', 'passthrough'),\n",
    "    ('preprocess', 'passthrough'),\n",
    "    ('model', 'passthrough')\n",
    "])\n",
    "\n",
    "params = [{\n",
    "    'scaler': [None, StandardScaler(), MinMaxScaler()],\n",
    "    \n",
    "    'preprocess': [None, \n",
    "             PolynomialFeatures(degree=2, include_bias=False),\n",
    "             PolynomialFeatures(degree=3, include_bias=False),\n",
    "             PolynomialFeatures(degree=4, include_bias=False)],\n",
    "    \n",
    "    'model': [Ridge(), Lasso()],\n",
    "    'model__alpha': powers\n",
    "}]\n",
    "\n",
    "regression = GridSearchCV(pipe, params, scoring='r2', cv=10, n_jobs = -1)\n",
    "\n",
    "regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('preprocess',\n",
      "                 PolynomialFeatures(degree=4, include_bias=False)),\n",
      "                ('model', Ridge(alpha=0.1))])\n",
      "R2: 0.851\n"
     ]
    }
   ],
   "source": [
    "print(regression.best_estimator_)\n",
    "\n",
    "best_model = regression.best_estimator_\n",
    "\n",
    "print (f'R2: {best_model.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# наилучшая модель при скоринге по R2 получается Ridge, c использованием полиномов и MinMax_Scaler\n",
    "# получилось значительно улучшить результат по сравнению с моделями без дополнительной обработки признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/adult-all.csv'\n",
    "data = pd.read_csv(link, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                 1       2          3   4                   5   \\\n",
       "0  39         State-gov   77516  Bachelors  13       Never-married   \n",
       "1  50  Self-emp-not-inc   83311  Bachelors  13  Married-civ-spouse   \n",
       "2  38           Private  215646    HS-grad   9            Divorced   \n",
       "3  53           Private  234721       11th   7  Married-civ-spouse   \n",
       "4  28           Private  338409  Bachelors  13  Married-civ-spouse   \n",
       "\n",
       "                  6              7      8       9     10  11  12  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male  2174   0  40   \n",
       "1    Exec-managerial        Husband  White    Male     0   0  13   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male     0   0  40   \n",
       "3  Handlers-cleaners        Husband  Black    Male     0   0  40   \n",
       "4     Prof-specialty           Wife  Black  Female     0   0  40   \n",
       "\n",
       "              13     14  \n",
       "0  United-States  <=50K  \n",
       "1  United-States  <=50K  \n",
       "2  United-States  <=50K  \n",
       "3  United-States  <=50K  \n",
       "4           Cuba  <=50K  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Разделите выборку на признаки и целевую переменную(колонка со зачениями {<=50K,>50K}). Замените целевую переменную на числовые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<=50K', '>50K'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[14].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = {'<=50K': 0, '>50K': 1}\n",
    "data[14] = data[14].map(di) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 0:14]\n",
    "y = data[14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Выясните, присутствуют ли в данных пропуски. Заполните их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пропусков нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Выберите колонки с числовыми и категориальными переменными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 10, 11, 12]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# числовые\n",
    "X.select_dtypes(include= ['number']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 6, 7, 8, 9, 13]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# категориальные\n",
    "X.select_dtypes(include= ['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_ix = X.select_dtypes(include=['number']).columns\n",
    "categorical_ix = X.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Создайте пайплайн по обработке колонок(используйте OneHotEncoder,MinMaxScaler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [('cat', OneHotEncoder(handle_unknown=\"ignore\"), categorical_ix), \n",
    "     ('num', MinMaxScaler(), numerical_ix)]\n",
    "\n",
    "col_transform = ColumnTransformer(transformers=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('prep', col_transform), ('m', model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Посчитайте метрики accuracy и f1_score на предсказании только самого частого класса в целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    37155\n",
       "1    11687\n",
       "Name: 14, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()\n",
    "\n",
    "# самый частый класс - 0 (<=50K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.zeros(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7607182343065395\n",
      "F1:  0.0\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy: ', accuracy_score(y, preds))\n",
    "print ('F1: ', f1_score(y, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Посчитайте cross_val_score по алгоритмам LogisticRegression, SVC, LinearSVC по метрикам accuracy и f1_score.\n",
    "Напишите удалось ли превзойти предыдущий результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy:  0.8516235077545211\n",
      "F1:  0.656652400058673\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "scores1 = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(pipeline, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('Logistic Regression')\n",
    "print ('Accuracy: ', scores1.mean())\n",
    "print ('F1: ', scores2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# использование логистической регрессии позволяет получить результат лучше, чем предсказание самого частого класса\n",
    "# LogReg, SVC и LinearSVC дают сопоставимые результаты. По качеству LogReg находится на 2м месте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "Accuracy:  0.8518486659172432\n",
      "F1:  0.6568048951654273\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC()\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "scores1 = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(pipeline, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('SVC')\n",
    "print ('Accuracy: ', scores1.mean())\n",
    "print ('F1: ', scores2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# использование SVC позволяет получить результат лучше, чем предсказание самого частого класса\n",
    "# LogReg, SVC и LinearSVC дают сопоставимые результаты. По качеству SVC находится на 1м месте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "Accuracy:  0.8513368826163095\n",
      "F1:  0.6572969769586605\n"
     ]
    }
   ],
   "source": [
    "model = svm.LinearSVC()\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "scores1 = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(pipeline, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('LinearSVC')\n",
    "print ('Accuracy: ', scores1.mean())\n",
    "print ('F1: ', scores2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# использование LinearSVC позволяет получить результат лучше, чем предсказание самого частого класса\n",
    "# LogReg, SVC и LinearSVC дают сопоставимые результаты. По качеству LinearSVC находится на 3м месте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Можно заметить что в данных присутствуют значения '?', замените их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='most_frequent', missing_values='?')\n",
    "imputer = imputer.fit(X)\n",
    "X.iloc[:,:] = imputer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Посчитайте cross_val_score на новых данных. Напишите удалось ли улучшить результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy:  0.8512962259738103\n",
      "F1:  0.6549104667898208\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "scores1 = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(pipeline, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('Logistic Regression')\n",
    "print ('Accuracy: ', scores1.mean())\n",
    "print ('F1: ', scores2.mean())\n",
    "\n",
    "# результат немного ухудшился"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "Accuracy:  0.8504360823091632\n",
      "F1:  0.6544201832303146\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC()\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "scores1 = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(pipeline, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('SVC')\n",
    "print ('Accuracy: ', scores1.mean())\n",
    "print ('F1: ', scores2.mean())\n",
    "\n",
    "# результат немного ухудшился"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "Accuracy:  0.850681769980644\n",
      "F1:  0.6548727121282654\n"
     ]
    }
   ],
   "source": [
    "model = svm.LinearSVC()\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "scores1 = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(pipeline, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('LinearSVC')\n",
    "print ('Accuracy: ', scores1.mean())\n",
    "print ('F1: ', scores2.mean())\n",
    "\n",
    "# результат немного ухудшился"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Посчитайте cross_val_score, если просто удалить значения '?'. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data[~(data == '?').any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new.iloc[:, 0:14]\n",
    "y = data_new[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy:  0.8475079653328221\n",
      "F1:  0.6607945464652485\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "scores1 = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(pipeline, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('Logistic Regression')\n",
    "print ('Accuracy: ', scores1.mean())\n",
    "print ('F1: ', scores2.mean())\n",
    "\n",
    "# результат ухудшился по accuracy и улучшился по F1\n",
    "# теперь LogReg на 3м месте по Accuracy и на 2м по F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "Accuracy:  0.8477508636138864\n",
      "F1:  0.6604485259315263\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC()\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "scores1 = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(pipeline, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('SVC')\n",
    "print ('Accuracy: ', scores1.mean())\n",
    "print ('F1: ', scores2.mean())\n",
    "\n",
    "# результат ухудшился по accuracy и улучшился по F1\n",
    "# теперь SVC на 2м месте по Accuracy и на 3м по F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "Accuracy:  0.8478395987367333\n",
      "F1:  0.6617526155405502\n"
     ]
    }
   ],
   "source": [
    "model = svm.LinearSVC()\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "scores1 = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(pipeline, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('LinearSVC')\n",
    "print ('Accuracy: ', scores1.mean())\n",
    "print ('F1: ', scores2.mean())\n",
    "\n",
    "# результат ухудшился по accuracy и улучшился по F1\n",
    "# теперь LinearSVC на 1м месте по обеим метрикам качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 17. Посчитайте cross_val_score для RandomForestClassifier,GradientBoostingClassifier. Напишите как изменился результат и какой вывод можно из этого сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 0:14]\n",
    "y = data[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "Accuracy:  0.8512141498528397\n",
      "F1:  0.6569180114541932\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "scores1 = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(pipeline, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('RandomForest')\n",
    "print ('Accuracy: ', scores1.mean())\n",
    "print ('F1: ', scores2.mean())\n",
    "\n",
    "# результаты в целом сопоставимы с предыдущими алгоритмами, но RandomForest позволяет немного улучшить качество\n",
    "# метрики RandomForest лучше, чем у GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting\n",
      "Accuracy:  0.8512140618333044\n",
      "F1:  0.6565322436257277\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "scores1 = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(pipeline, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('GradientBoosting')\n",
    "print ('Accuracy: ', scores1.mean())\n",
    "print ('F1: ', scores2.mean())\n",
    "\n",
    "# результаты сопоставимы с предыдущими алгоритмами, но GradientBoosting позволяет немного улучшить качество"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Подберите наилучшую модель, подбирая методы обработки колонок - масштабирование признаков, кодирование признаков и заполнение пропусков. Параметры алгоритмов оставьте по умолчанию. Выведите итоговые параметры и результат accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = data.iloc[:, 0:14]\n",
    "y = data[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('prep', 'passthrough'),\n",
       "                                       ('model', 'passthrough')]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'model': [LogisticRegression(), SVC(), LinearSVC(),\n",
       "                                    RandomForestClassifier(),\n",
       "                                    GradientBoostingClassifier()],\n",
       "                          'prep': [ColumnTransformer(transformers=[('cat',\n",
       "                                                                    OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                                    Int64Index([1, 3, 5, 6, 7, 8, 9, 13], dtype='int64')),\n",
       "                                                                   ('num',\n",
       "                                                                    MinMaxScaler(),\n",
       "                                                                    Int64Index([0, 2, 4, 10, 11, 12], dtype='int64'))]),\n",
       "                                   ColumnTransformer(transformers=[('cat',\n",
       "                                                                    OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                                    Int64Index([1, 3, 5, 6, 7, 8, 9, 13], dtype='int64')),\n",
       "                                                                   ('num',\n",
       "                                                                    StandardScaler(),\n",
       "                                                                    Int64Index([0, 2, 4, 10, 11, 12], dtype='int64'))])]}],\n",
       "             refit='f1', scoring=['accuracy', 'f1'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# оставляем пропуски как есть\n",
    "\n",
    "X = data.iloc[:, 0:14]\n",
    "y = data[14]\n",
    "\n",
    "t1 = [('cat', OneHotEncoder(handle_unknown=\"ignore\"), categorical_ix), \n",
    "     ('num', MinMaxScaler(), numerical_ix)]\n",
    "\n",
    "t2 = [('cat', OneHotEncoder(handle_unknown=\"ignore\"), categorical_ix), \n",
    "     ('num', StandardScaler(), numerical_ix)]\n",
    "\n",
    "col_transform1 = ColumnTransformer(transformers=t1)\n",
    "col_transform2 = ColumnTransformer(transformers=t2)\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('prep', 'passthrough'),\n",
    "    ('model', 'passthrough')\n",
    "])\n",
    "\n",
    "params = [{\n",
    "    'prep': [col_transform1, col_transform2],\n",
    "    \n",
    "    'model': [LogisticRegression(),\n",
    "              svm.SVC(),\n",
    "              svm.LinearSVC(),\n",
    "              RandomForestClassifier(),\n",
    "              GradientBoostingClassifier()            \n",
    "            ]\n",
    "}]\n",
    "\n",
    "regression = GridSearchCV(pipe, params, scoring=['accuracy', 'f1'], refit = 'f1', cv=10, n_jobs = -1)\n",
    "\n",
    "regression.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('prep',\n",
      "                 ColumnTransformer(transformers=[('cat',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  Int64Index([1, 3, 5, 6, 7, 8, 9, 13], dtype='int64')),\n",
      "                                                 ('num', MinMaxScaler(),\n",
      "                                                  Int64Index([0, 2, 4, 10, 11, 12], dtype='int64'))])),\n",
      "                ('model', GradientBoostingClassifier())])\n"
     ]
    }
   ],
   "source": [
    "print(regression.best_estimator_)\n",
    "best_model = regression.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>rank_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'model': GradientBoostingClassifier(), 'prep'...</td>\n",
       "      <td>0.687155</td>\n",
       "      <td>0.867901</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'model': GradientBoostingClassifier(), 'prep'...</td>\n",
       "      <td>0.687122</td>\n",
       "      <td>0.867880</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'model': RandomForestClassifier(), 'prep': Co...</td>\n",
       "      <td>0.669056</td>\n",
       "      <td>0.853180</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'model': RandomForestClassifier(), 'prep': Co...</td>\n",
       "      <td>0.668436</td>\n",
       "      <td>0.853057</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'model': SVC(), 'prep': ColumnTransformer(tra...</td>\n",
       "      <td>0.663146</td>\n",
       "      <td>0.857193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_test_f1  \\\n",
       "0  {'model': GradientBoostingClassifier(), 'prep'...      0.687155   \n",
       "1  {'model': GradientBoostingClassifier(), 'prep'...      0.687122   \n",
       "2  {'model': RandomForestClassifier(), 'prep': Co...      0.669056   \n",
       "3  {'model': RandomForestClassifier(), 'prep': Co...      0.668436   \n",
       "4  {'model': SVC(), 'prep': ColumnTransformer(tra...      0.663146   \n",
       "\n",
       "   mean_test_accuracy  rank_test_f1  \n",
       "0            0.867901             1  \n",
       "1            0.867880             2  \n",
       "2            0.853180             3  \n",
       "3            0.853057             4  \n",
       "4            0.857193             5  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_scores=pd.DataFrame(regression.cv_results_).sort_values(by='rank_test_f1').reset_index()\n",
    "\n",
    "df_cv_scores[['params','mean_test_f1', 'mean_test_accuracy', 'rank_test_f1']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.867900654446202\n",
      "F1:  0.6871548063849853\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy: ', df_cv_scores.loc[0,'mean_test_accuracy'])\n",
    "print ('F1: ', df_cv_scores.loc[0,'mean_test_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# науилучший результат получается при использовании GradientBoosting, не используя замены/удаления пропусков (см.ниже)\n",
    "# для категориальных признаков используем OneHotEncoder, для числовых - MinMax_Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('prep', 'passthrough'),\n",
       "                                       ('model', 'passthrough')]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'model': [LogisticRegression(), SVC(), LinearSVC(),\n",
       "                                    RandomForestClassifier(),\n",
       "                                    GradientBoostingClassifier()],\n",
       "                          'prep': [ColumnTransformer(transformers=[('cat',\n",
       "                                                                    OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                                    Int64Index([1, 3, 5, 6, 7, 8, 9, 13], dtype='int64')),\n",
       "                                                                   ('num',\n",
       "                                                                    MinMaxScaler(),\n",
       "                                                                    Int64Index([0, 2, 4, 10, 11, 12], dtype='int64'))]),\n",
       "                                   ColumnTransformer(transformers=[('cat',\n",
       "                                                                    OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                                    Int64Index([1, 3, 5, 6, 7, 8, 9, 13], dtype='int64')),\n",
       "                                                                   ('num',\n",
       "                                                                    StandardScaler(),\n",
       "                                                                    Int64Index([0, 2, 4, 10, 11, 12], dtype='int64'))])]}],\n",
       "             refit='f1', scoring=['accuracy', 'f1'])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# заменям пропуски на most_frequent\n",
    "\n",
    "X = data.iloc[:, 0:14]\n",
    "y = data[14]\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent', missing_values='?')\n",
    "imputer = imputer.fit(X)\n",
    "X.iloc[:,:] = imputer.transform(X)\n",
    "\n",
    "\n",
    "t1 = [('cat', OneHotEncoder(handle_unknown=\"ignore\"), categorical_ix), \n",
    "     ('num', MinMaxScaler(), numerical_ix)]\n",
    "\n",
    "t2 = [('cat', OneHotEncoder(handle_unknown=\"ignore\"), categorical_ix), \n",
    "     ('num', StandardScaler(), numerical_ix)]\n",
    "\n",
    "col_transform1 = ColumnTransformer(transformers=t1)\n",
    "col_transform2 = ColumnTransformer(transformers=t2)\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('prep', 'passthrough'),\n",
    "    ('model', 'passthrough')\n",
    "])\n",
    "\n",
    "params = [{\n",
    "    'prep': [col_transform1, col_transform2],\n",
    "    \n",
    "    'model': [LogisticRegression(),\n",
    "              svm.SVC(),\n",
    "              svm.LinearSVC(),\n",
    "              RandomForestClassifier(),\n",
    "              GradientBoostingClassifier()            \n",
    "            ]\n",
    "}]\n",
    "\n",
    "regression2 = GridSearchCV(pipe, params, scoring=['accuracy', 'f1'], refit = 'f1', cv=10, n_jobs = -1)\n",
    "\n",
    "regression2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>rank_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'model': GradientBoostingClassifier(), 'prep'...</td>\n",
       "      <td>0.681732</td>\n",
       "      <td>0.866242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'model': GradientBoostingClassifier(), 'prep'...</td>\n",
       "      <td>0.681698</td>\n",
       "      <td>0.866222</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'model': RandomForestClassifier(), 'prep': Co...</td>\n",
       "      <td>0.667265</td>\n",
       "      <td>0.852299</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'model': RandomForestClassifier(), 'prep': Co...</td>\n",
       "      <td>0.666443</td>\n",
       "      <td>0.852115</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'model': SVC(), 'prep': ColumnTransformer(tra...</td>\n",
       "      <td>0.660625</td>\n",
       "      <td>0.856517</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_test_f1  \\\n",
       "8  {'model': GradientBoostingClassifier(), 'prep'...      0.681732   \n",
       "9  {'model': GradientBoostingClassifier(), 'prep'...      0.681698   \n",
       "6  {'model': RandomForestClassifier(), 'prep': Co...      0.667265   \n",
       "7  {'model': RandomForestClassifier(), 'prep': Co...      0.666443   \n",
       "3  {'model': SVC(), 'prep': ColumnTransformer(tra...      0.660625   \n",
       "\n",
       "   mean_test_accuracy  rank_test_f1  \n",
       "8            0.866242             1  \n",
       "9            0.866222             2  \n",
       "6            0.852299             3  \n",
       "7            0.852115             4  \n",
       "3            0.856517             5  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_scores2=pd.DataFrame(regression2.cv_results_).sort_values(by='rank_test_f1')\n",
    "\n",
    "df_cv_scores2[['params','mean_test_f1', 'mean_test_accuracy', 'rank_test_f1']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('prep',\n",
      "                 ColumnTransformer(transformers=[('cat',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  Int64Index([1, 3, 5, 6, 7, 8, 9, 13], dtype='int64')),\n",
      "                                                 ('num', MinMaxScaler(),\n",
      "                                                  Int64Index([0, 2, 4, 10, 11, 12], dtype='int64'))])),\n",
      "                ('model', GradientBoostingClassifier())])\n"
     ]
    }
   ],
   "source": [
    "print(regression2.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# науилучший результат получается при использовании GradientBoosting\n",
    "# замена пропусков на most_frequent немного снижает качество\n",
    "# для категориальных признаков используем OneHotEncoder, для числовых - MinMax_Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('prep', 'passthrough'),\n",
       "                                       ('model', 'passthrough')]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'model': [LogisticRegression(), SVC(), LinearSVC(),\n",
       "                                    RandomForestClassifier(),\n",
       "                                    GradientBoostingClassifier()],\n",
       "                          'prep': [ColumnTransformer(transformers=[('cat',\n",
       "                                                                    OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                                    Int64Index([1, 3, 5, 6, 7, 8, 9, 13], dtype='int64')),\n",
       "                                                                   ('num',\n",
       "                                                                    MinMaxScaler(),\n",
       "                                                                    Int64Index([0, 2, 4, 10, 11, 12], dtype='int64'))]),\n",
       "                                   ColumnTransformer(transformers=[('cat',\n",
       "                                                                    OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                                    Int64Index([1, 3, 5, 6, 7, 8, 9, 13], dtype='int64')),\n",
       "                                                                   ('num',\n",
       "                                                                    StandardScaler(),\n",
       "                                                                    Int64Index([0, 2, 4, 10, 11, 12], dtype='int64'))])]}],\n",
       "             refit='f1', scoring=['accuracy', 'f1'])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# удаляем пропуски\n",
    "\n",
    "X_new = data_new.iloc[:, 0:14]\n",
    "y_new = data_new[14]\n",
    "\n",
    "t1 = [('cat', OneHotEncoder(handle_unknown=\"ignore\"), categorical_ix), \n",
    "     ('num', MinMaxScaler(), numerical_ix)]\n",
    "\n",
    "t2 = [('cat', OneHotEncoder(handle_unknown=\"ignore\"), categorical_ix), \n",
    "     ('num', StandardScaler(), numerical_ix)]\n",
    "\n",
    "col_transform1 = ColumnTransformer(transformers=t1)\n",
    "col_transform2 = ColumnTransformer(transformers=t2)\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('prep', 'passthrough'),\n",
    "    ('model', 'passthrough')\n",
    "])\n",
    "\n",
    "params = [{\n",
    "    'prep': [col_transform1, col_transform2],\n",
    "    \n",
    "    'model': [LogisticRegression(),\n",
    "              svm.SVC(),\n",
    "              svm.LinearSVC(),\n",
    "              RandomForestClassifier(),\n",
    "              GradientBoostingClassifier()            \n",
    "            ]\n",
    "}]\n",
    "\n",
    "regression3 = GridSearchCV(pipe, params, scoring=['accuracy', 'f1'], refit = 'f1', cv=10, n_jobs = -1)\n",
    "\n",
    "regression3.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>rank_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'model': GradientBoostingClassifier(), 'prep'...</td>\n",
       "      <td>0.681763</td>\n",
       "      <td>0.866242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'model': GradientBoostingClassifier(), 'prep'...</td>\n",
       "      <td>0.681668</td>\n",
       "      <td>0.866222</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'model': RandomForestClassifier(), 'prep': Co...</td>\n",
       "      <td>0.671646</td>\n",
       "      <td>0.854551</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'model': RandomForestClassifier(), 'prep': Co...</td>\n",
       "      <td>0.668899</td>\n",
       "      <td>0.853139</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'model': SVC(), 'prep': ColumnTransformer(tra...</td>\n",
       "      <td>0.660625</td>\n",
       "      <td>0.856517</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_test_f1  \\\n",
       "8  {'model': GradientBoostingClassifier(), 'prep'...      0.681763   \n",
       "9  {'model': GradientBoostingClassifier(), 'prep'...      0.681668   \n",
       "7  {'model': RandomForestClassifier(), 'prep': Co...      0.671646   \n",
       "6  {'model': RandomForestClassifier(), 'prep': Co...      0.668899   \n",
       "3  {'model': SVC(), 'prep': ColumnTransformer(tra...      0.660625   \n",
       "\n",
       "   mean_test_accuracy  rank_test_f1  \n",
       "8            0.866242             1  \n",
       "9            0.866222             2  \n",
       "7            0.854551             3  \n",
       "6            0.853139             4  \n",
       "3            0.856517             5  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_scores3=pd.DataFrame(regression3.cv_results_).sort_values(by='rank_test_f1')\n",
    "\n",
    "df_cv_scores3[['params','mean_test_f1', 'mean_test_accuracy', 'rank_test_f1']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('prep',\n",
      "                 ColumnTransformer(transformers=[('cat',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  Int64Index([1, 3, 5, 6, 7, 8, 9, 13], dtype='int64')),\n",
      "                                                 ('num', MinMaxScaler(),\n",
      "                                                  Int64Index([0, 2, 4, 10, 11, 12], dtype='int64'))])),\n",
      "                ('model', GradientBoostingClassifier())])\n"
     ]
    }
   ],
   "source": [
    "print(regression3.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# науилучший результат получается при использовании GradientBoosting\n",
    "# удаление пропусков немного снижает качество\n",
    "# для категориальных признаков используем OneHotEncoder, для числовых - MinMax_Scaler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
