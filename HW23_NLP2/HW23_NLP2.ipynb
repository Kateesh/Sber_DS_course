{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYZRf1ncz-sT"
   },
   "source": [
    "# NLP2_1\n",
    "https://www.hackerrank.com/challenges/detect-the-email-addresses/problem?isFullScreen=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect the Email Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = '''19\n",
    "HackerRank is more than just a company\n",
    "    We are a tight group of hackers, bootstrappers, entrepreneurial thinkers and innovators. We are building an engaged community of problem solvers. Imagine the intelligence and value that a room would hold if it contained hackers/problem solvers from around the world? We're building this online.\n",
    "Hypothesis: Every hacker loves a particular type of challenge presented in a certain set of difficulty. If we build a large collection of real world challenges in different domains with an engaging interface, it is going to be incredible! Join us to create history.\n",
    "Available Positions\n",
    "Product Hacker product@hackerrank.com\n",
    "Challenge Curator\n",
    "Product Evangelist\n",
    "Product Designer\n",
    "Content Creator\n",
    "ACM World Finals Hacker\n",
    "Backend C++ Hacker\n",
    "Mail us at hackers@hackerrank.com to chat more. Or you can write to us at interviewstreet@hackerrank.com!\n",
    "HACKERRANK PERKS\n",
    "Working for a startup is hard work, but there are plenty of benefits of working for a small, fun, growing team.\n",
    "[Image] Perk: Get tools for the jobAll the Right ToolsWe know that everyone's perfect workspace is unique to them. We will get you set up with whatever equipment you need to start hacking - a new 15” Macbook Pro or iMac, or a computer of your choice plus a display if you need it. Additionally, if you require any software or other tools, we've got it covered.[Image] Perk: Flexible HoursFlexible HoursBecause we work so hard, we encourage our employees to keep flexible hours and don't require them to track their time. A morning scrum and open communication ensures that the job gets done on time, and we rely on the honor system so that you can work on your own pace.[Image] Perk: HealthcareWellness SupportTo work hard, you have to be healthy. We will cover your health, dental, and visual insurance with no wait period. That means instant benefits from the day you're hired.[Image] Perk: Choice of LocationLocation, Location, LocationWe are the first Indian company to be backed by Y-Combinator, and as a result we have a thriving office in Bangalore and a growing office in Mountain View, CA. Depending on your residency or visa status, we will get you situated in one of our two offices, both of which are located in the heart of their country's tech industry.[Image] Perk: Choice of LocationCreative SupportIf you have a cool side project that you want to launch, we will pay for EC2/heroku servers to get it off the ground. Side projects fuel creativity and learning, which are crucial to the HackerRank culture.\n",
    "CULTURE\n",
    "The culture of a startup is reflective of the founders’ DNA. Larry Page & Sergey Brin were PhD’s from Stanford and that’s why Google is filled with high scoring graders from top schools and is very hard to get in if you’re not a CS major. Similarly, the hacker culture at Facebook is inspired by Zuckerberg, a hacker, the design culture by Steve Jobs and so on.\n",
    "The adjective to describe the environment/founders here is relentless hardworkers. It might be a general trait of a startup but I’m pretty sure it’s a notch higher here and defines the culture. This is what has taken us this far. It’s not working in weekends or allnighters that count, but the effort that goes into building something intellectually engaging for hackers and making it fun is high.\n",
    "You’ll have to embrace randomness and chaos. There’s some level of discipline (eg: daily scrums) but only so much. We push boundaries everyday, stretch our limits but no one complains because there’s a feeling of doing something great at the end of the day, every single day.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hackers@hackerrank.com;interviewstreet@hackerrank.com;product@hackerrank.com\n"
     ]
    }
   ],
   "source": [
    "reg_pat = r'([\\w0-9-._]+@[\\w0-9-.]+[\\w0-9]{1,10})'\n",
    "\n",
    "import re\n",
    "import sys\n",
    "\n",
    "data = [line for line in sample_input]\n",
    "\n",
    "result = []\n",
    "ss = ''\n",
    "\n",
    "if re.findall(reg_pat, sample_input) is not None:\n",
    "    result = re.findall(reg_pat, sample_input)\n",
    "\n",
    "ss = ';'.join(sorted(set(result)))\n",
    "\n",
    "print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKzbIfdq0CKr"
   },
   "source": [
    "# NLP2_2 \n",
    "https://www.hackerrank.com/challenges/detect-the-domain-name/problem?isFullScreen=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect the domain name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input2 = '''10\n",
    "<div class=\"reflist\" style=\"list-style-type: decimal;\">\n",
    "<ol class=\"references\">\n",
    "<li id=\"cite_note-1\"><span class=\"mw-cite-backlink\"><b>^ [\"Train (noun)\"](http://www.askoxford.com/concise_oed/train?view=uk). <i>(definition – Compact OED)</i>. Oxford University Press<span class=\"reference-accessdate\">. Retrieved 2008-03-18</span>.</span><span title=\"ctx_ver=Z39.88-2004&rfr_id=info%3Asid%2Fen.wikipedia.org%3ATrain&rft.atitle=Train+%28noun%29&rft.genre=article&rft_id=http%3A%2F%2Fwww.askoxford.com%2Fconcise_oed%2Ftrain%3Fview%3Duk&rft.jtitle=%28definition+%E2%80%93+Compact+OED%29&rft.pub=Oxford+University+Press&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal\" class=\"Z3988\"><span style=\"display:none;\"> </span></span></span></li>\n",
    "<li id=\"cite_note-2\"><span class=\"mw-cite-backlink\"><b>^</b></span> <span class=\"reference-text\"><span class=\"citation book\">Atchison, Topeka and Santa Fe Railway (1948). <i>Rules: Operating Department</i>. p. 7.</span><span title=\"ctx_ver=Z39.88-2004&rfr_id=info%3Asid%2Fen.wikipedia.org%3ATrain&rft.au=Atchison%2C+Topeka+and+Santa+Fe+Railway&rft.aulast=Atchison%2C+Topeka+and+Santa+Fe+Railway&rft.btitle=Rules%3A+Operating+Department&rft.date=1948&rft.genre=book&rft.pages=7&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook\" class=\"Z3988\"><span style=\"display:none;\"> </span></span></span></li>\n",
    "<li id=\"cite_note-3\"><span class=\"mw-cite-backlink\"><b>^ [Hydrogen trains](http://www.hydrogencarsnow.com/blog2/index.php/hydrogen-vehicles/i-hear-the-hydrogen-train-a-comin-its-rolling-round-the-bend/)</span></li>\n",
    "<li id=\"cite_note-4\"><span class=\"mw-cite-backlink\"><b>^ [Vehicle Projects Inc. Fuel cell locomotive](http://www.bnsf.com/media/news/articles/2008/01/2008-01-09a.html)</span></li>\n",
    "<li id=\"cite_note-5\"><span class=\"mw-cite-backlink\"><b>^</b></span> <span class=\"reference-text\"><span class=\"citation book\">Central Japan Railway (2006). <i>Central Japan Railway Data Book 2006</i>. p. 16.</span><span title=\"ctx_ver=Z39.88-2004&rfr_id=info%3Asid%2Fen.wikipedia.org%3ATrain&rft.au=Central+Japan+Railway&rft.aulast=Central+Japan+Railway&rft.btitle=Central+Japan+Railway+Data+Book+2006&rft.date=2006&rft.genre=book&rft.pages=16&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook\" class=\"Z3988\"><span style=\"display:none;\"> </span></span></span></li>\n",
    "<li id=\"cite_note-6\"><span class=\"mw-cite-backlink\"><b>^ [\"Overview Of the existing Mumbai Suburban Railway\"](http://web.archive.org/web/20080620033027/http://www.mrvc.indianrail.gov.in/overview.htm). _Official webpage of Mumbai Railway Vikas Corporation_. Archived from [the original](http://www.mrvc.indianrail.gov.in/overview.htm) on 2008-06-20<span class=\"reference-accessdate\">. Retrieved 2008-12-11</span>.</span><span title=\"ctx_ver=Z39.88-2004&rfr_id=info%3Asid%2Fen.wikipedia.org%3ATrain&rft.atitle=Overview+Of+the+existing+Mumbai+Suburban+Railway&rft.genre=article&rft_id=http%3A%2F%2Fwww.mrvc.indianrail.gov.in%2Foverview.htm&rft.jtitle=Official+webpage+of+Mumbai+Railway+Vikas+Corporation&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal\" class=\"Z3988\"><span style=\"display:none;\"> </span></span></span></li>\n",
    "</ol>\n",
    "</div>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "askoxford.com;bnsf.com;hydrogencarsnow.com;mrvc.indianrail.gov.in;web.archive.org\n"
     ]
    }
   ],
   "source": [
    "reg_pat = r'http?://(?:ww[w2]\\.){0,10}([\\w\\d\\-\\.]*\\.\\w+){0,10}'\n",
    "\n",
    "data = sample_input2\n",
    "\n",
    "result = []\n",
    "ss = ''\n",
    "\n",
    "x = re.findall(reg_pat, data) \n",
    "\n",
    "\n",
    "for item in x:\n",
    "    xx = re.sub('https://','',item)\n",
    "    xxx = re.sub('http://','',xx)\n",
    "    xxxx = re.sub('www.','',xxx)\n",
    "    result.append(xxxx)\n",
    "\n",
    "ss = ';'.join(sorted(set(result)))\n",
    "\n",
    "print(ss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5DQQnoU1bXY"
   },
   "source": [
    "# NLP2_3 Реализовать классификатор токсичных комментариев tfidf на базе датасета\n",
    "https://www.kaggle.com/datasets/blackmoon/russian-language-toxic-comments  \n",
    "\n",
    "Дубликат файла: https://cloud.mail.ru/public/Z4L3/vB8GcgTtK\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import nltk\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"labeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['toxic'] = df['toxic'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic\n",
       "0               Верблюдов-то за что? Дебилы, бл...\\n      1\n",
       "1  Хохлы, это отдушина затюканого россиянина, мол...      1\n",
       "2                          Собаке - собачья смерть\\n      1\n",
       "3  Страницу обнови, дебил. Это тоже не оскорблени...      1\n",
       "4  тебя не убедил 6-страничный пдф в том, что Скр...      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14412, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9586\n",
       "1    4826\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(df, test_size = 3600, random_state = 0)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the count vectorizer\n",
    "count = CountVectorizer()\n",
    "word_count=count.fit_transform(list(train_data['comment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "features = vectorizer.fit_transform(train_data['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state = 0)\n",
    "model.fit(features, train_data['toxic']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                ('model', LogisticRegression(random_state=0))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('model', LogisticRegression(random_state = 0))\n",
    "])\n",
    "\n",
    "model_pipeline.fit(train_data['comment'], train_data['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8569444444444444\n",
      "Precision: 0.8653846153846154\n",
      "Recall: 0.6755629691409508\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_score(test_data['toxic'], model_pipeline.predict(test_data['comment']))}\")\n",
    "print(f\"Precision: {precision_score(test_data['toxic'], model_pipeline.predict(test_data['comment']))}\")\n",
    "print(f\"Recall: {recall_score(test_data['toxic'], model_pipeline.predict(test_data['comment']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count)\n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=count.get_feature_names(),columns=[\"idf_weights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>не</th>\n",
       "      <td>1.870911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>на</th>\n",
       "      <td>2.167916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>что</th>\n",
       "      <td>2.298944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>это</th>\n",
       "      <td>2.573827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>то</th>\n",
       "      <td>2.656588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>марголиус</th>\n",
       "      <td>9.595357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>маргоша</th>\n",
       "      <td>9.595357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>марджинал</th>\n",
       "      <td>9.595357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>метастазы</th>\n",
       "      <td>9.595357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ётавских</th>\n",
       "      <td>9.595357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56948 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           idf_weights\n",
       "не            1.870911\n",
       "на            2.167916\n",
       "что           2.298944\n",
       "это           2.573827\n",
       "то            2.656588\n",
       "...                ...\n",
       "марголиус     9.595357\n",
       "маргоша       9.595357\n",
       "марджинал     9.595357\n",
       "метастазы     9.595357\n",
       "ётавских      9.595357\n",
       "\n",
       "[56948 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inverse document frequency\n",
    "df_idf.sort_values(by=['idf_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>снеговик</th>\n",
       "      <td>0.472214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>сделаем</th>\n",
       "      <td>0.427121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>солдаты</th>\n",
       "      <td>0.418148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>сделают</th>\n",
       "      <td>0.398194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>нато</th>\n",
       "      <td>0.369879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>клиентам</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>клиентов</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>клиентом</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>клиентоориентированность</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ётавских</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56948 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             tfidf\n",
       "снеговик                  0.472214\n",
       "сделаем                   0.427121\n",
       "солдаты                   0.418148\n",
       "сделают                   0.398194\n",
       "нато                      0.369879\n",
       "...                            ...\n",
       "клиентам                  0.000000\n",
       "клиентов                  0.000000\n",
       "клиентом                  0.000000\n",
       "клиентоориентированность  0.000000\n",
       "ётавских                  0.000000\n",
       "\n",
       "[56948 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf\n",
    "tf_idf_vector=tfidf_transformer.transform(word_count)\n",
    "feature_names = count.get_feature_names()\n",
    "first_document_vector=tf_idf_vector[1]\n",
    "df_tfifd= pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"])\n",
    "df_tfifd.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "features = vectorizer.fit_transform(train_data['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state = 0)\n",
    "model.fit(features, train_data['toxic']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                ('model', LogisticRegression(random_state=0))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('model', LogisticRegression(random_state = 0))\n",
    "])\n",
    "\n",
    "model_pipeline.fit(train_data['comment'], train_data['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline.predict([\"Тупое мнение\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline.predict([\"Как пройти до Красной площади\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8322222222222222\n",
      "Precision: 0.9092159559834938\n",
      "Recall: 0.5512927439532944\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_score(test_data['toxic'], model_pipeline.predict(test_data['comment']))}\")\n",
    "print(f\"Precision: {precision_score(test_data['toxic'], model_pipeline.predict(test_data['comment']))}\")\n",
    "print(f\"Recall: {recall_score(test_data['toxic'], model_pipeline.predict(test_data['comment']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0BRC1-k81pIW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "NLP2-homework",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
