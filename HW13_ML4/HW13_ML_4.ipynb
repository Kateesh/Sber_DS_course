{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/ml/datasets/wine+quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "data = pd.read_csv('winequality-red.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 0:11]\n",
    "y = data['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Оцените качество по метрике accuracy для классификаторов:\n",
    "\n",
    "DecisionTreeClassifier\n",
    "\n",
    "BaggingClassifier со 100 деревьями\n",
    "\n",
    "RandomForestClassifier со 100 деревьями\n",
    "\n",
    "Сравните результаты и напишите какой вывод можно сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, STATUS_FAIL, Trials\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_dtc 0.4777830188679245\n",
      "accuracy_bc 0.5578301886792453\n",
      "accuracy_rfc 0.5734905660377358\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "dtc.fit(X, y)\n",
    "\n",
    "bc = BaggingClassifier(n_estimators=100, random_state=42)\n",
    "bc.fit(X, y)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(X, y)\n",
    "\n",
    "print('accuracy_dtc',  cross_val_score(dtc, X, y, cv=10, scoring = 'accuracy').mean())\n",
    "print('accuracy_bc',  cross_val_score(bc, X, y, cv=10, scoring = 'accuracy').mean())\n",
    "print('accuracy_rfc',  cross_val_score(rfc, X, y, cv=10, scoring = 'accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# наилучший результат показал RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Разделите выборку на обучающую и тестовую в отношении 70%/30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1119, 11), (480, 11), (1119,), (480,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify = y)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Посчитайте качество на тестовой выборке по метрике accuracy для классификатора RandomForestClassifier, используя значения деревьев:\n",
    "    \n",
    "10, 50, 100, 200, далее с шагом 200 до 5000 деревьев.\n",
    "Постройте график зависимости качества от числа деревьев.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = [10,50,100]\n",
    "\n",
    "for i in range(200,5001,200):\n",
    "    trees.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.DataFrame()\n",
    "i = 0\n",
    "\n",
    "for val in trees:\n",
    "    model = BaggingClassifier(n_estimators=val, random_state = 42, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    df.loc[i, 'trees'] = val\n",
    "    df.loc[i, 'accuracy'] = accuracy_score(y_test, y_pred)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trees</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.643750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.658333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400.0</td>\n",
       "      <td>0.672917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trees  accuracy\n",
       "0   10.0  0.643750\n",
       "1   50.0  0.650000\n",
       "2  100.0  0.658333\n",
       "3  200.0  0.662500\n",
       "4  400.0  0.672917"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df['trees'], df['accuracy'])\n",
    "plt.xlabel('trees', size=20)\n",
    "plt.ylabel('accuracy', size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Обучите реализации градиентного бустинга с параметрами по умолчанию из библиотек sklearn и xgboost. Сравните значение метрики accuracy по cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:29:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skl = GradientBoostingClassifier()\n",
    "skl.fit(X_train, y_train)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:29:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:29:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:29:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:29:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:29:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:29:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:29:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:29:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:29:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:29:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "------------------------------\n",
      "accuracy_sklearn 0.6125\n",
      "accuracy_xgboost 0.59375\n"
     ]
    }
   ],
   "source": [
    "acc_xgb = cross_val_score(xgb, X_test, y_test, cv=10, scoring = 'accuracy').mean()\n",
    "\n",
    "print ('------------------------------')\n",
    "print('accuracy_sklearn',  cross_val_score(skl, X_test, y_test, cv=10, scoring = 'accuracy').mean())\n",
    "print('accuracy_xgboost',  acc_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# реализация gradient boosting в sklearn показала результат немного лучше, по сравнению с xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Подберите оптимальные параметры этих алгоритмов с помощью GridSearchCV(cv=3).\n",
    "Параметры для оптимизации:\n",
    "\n",
    "оптимизируемый функционал\n",
    "\n",
    "скорость обучения\n",
    "\n",
    "количество деревьев\n",
    "\n",
    "глубина деревьев\n",
    "\n",
    "Сравните значение метрики accuracy и скорость работы. Выведите лучшие параметры алгоритмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'learning_rate':np.linspace(0.01, 1, 10),\n",
    "        'max_depth': range(1,10),\n",
    "        'n_estimators': range(1,50,5)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n",
      "{'learning_rate': 0.23, 'max_depth': 9, 'n_estimators': 46}\n",
      "Wall time: 10min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gbc = GradientBoostingClassifier()\n",
    "search = GridSearchCV(gbc, params, scoring='accuracy', n_jobs=-1, cv=3)\n",
    "\n",
    "gbc_fit = search.fit(X_train, y_train)\n",
    "print(\"Accuracy:\", gbc_fit.score(X_test, y_test))\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:51:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.6416666666666667\n",
      "{'learning_rate': 0.56, 'max_depth': 5, 'n_estimators': 31}\n",
      "Wall time: 6min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier()\n",
    "search2 = GridSearchCV(xgb, params, scoring='accuracy', n_jobs=-1, cv=3)\n",
    "\n",
    "xgb_fit = search2.fit(X_train, y_train)\n",
    "print(\"Accuracy:\", xgb_fit.score(X_test, y_test))\n",
    "print(search2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подбор параметров позволил улучшить качество обоих алгоритмов\n",
    "# лучший результат также показала реализация sklearn \n",
    "# однако подбор параметров для этого алгоритма занял больше времени"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Обучите реализации градиентного бустинга с параметрами по умолчанию из библиотек lightgbm и catboost. Сравните значение метрики accuracy по cross_val_score по всем четырем реализациям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "accuracy 0.6187500000000001\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "lgb = LGBMClassifier()\n",
    "\n",
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "print('accuracy',  cross_val_score(lgb, X_test, y_test, cv=10,scoring = 'accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "accuracy 0.6187500000000001\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "ctb = CatBoostClassifier(verbose = 0)\n",
    "\n",
    "ctb.fit(X_train, y_train)\n",
    "\n",
    "print('accuracy',  cross_val_score(ctb, X_test, y_test, cv=10,scoring = 'accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# качество LightGBM и Catboost практически не отличается\n",
    "# без подбора параметров эти алгоритмы показывают самый лучший результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.Подберите оптимальные параметры для алгоритмов градиентного бустинга из библиотек lightgbm и catboost с теми же условиями. Выведите лучшие параметры алгоритмов.\n",
    "Сравните значение метрики accuracy и скорость по этим четырем реализациям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6458333333333334\n",
      "{'learning_rate': 0.34, 'max_depth': 5, 'n_estimators': 26}\n",
      "Wall time: 5min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb = LGBMClassifier()\n",
    "search = GridSearchCV(lgb, params, scoring='accuracy', n_jobs=-1, cv=3)\n",
    "\n",
    "lgb_fit = search.fit(X_train, y_train)\n",
    "print(\"Accuracy:\", lgb_fit.score(X_test, y_test))\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6479166666666667\n",
      "{'learning_rate': 0.45, 'max_depth': 9, 'n_estimators': 36}\n",
      "Wall time: 12min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ctb = CatBoostClassifier(verbose = 0)\n",
    "search = GridSearchCV(ctb, params, scoring='accuracy', n_jobs=-1, cv=3)\n",
    "\n",
    "ctb_fit = search.fit(X_train, y_train)\n",
    "print(\"Accuracy:\", ctb_fit.score(X_test, y_test))\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# качество LightGBM и Catboost улучшилось после подбора параметров, однако осталось практически одинаковым\n",
    "# самый лучший результат остался у реализации sklearn, а LightGBM и Catboost заняли 2-3 место"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.Подберите оптимальные параметры алгоритма из библиотеки xgbost с помощью [hyperopt](https://github.com/hyperopt/hyperopt) . Параметры для оптимизации:\n",
    "\n",
    "оптимизируемый функционал\n",
    "\n",
    "скорость обучения\n",
    "\n",
    "количество деревьев\n",
    "\n",
    "глубина деревьев\n",
    "\n",
    "Сравните результат с поиском по сетке из sklearn. Выведите лучшие параметры алгоритма, найденные даным способом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "space={       \n",
    "        'learning_rate':    hp.choice('learning_rate',    np.arange(0.01, 1, 0.1)),\n",
    "        'max_depth':        hp.choice('max_depth',        np.arange(1, 10, 1, dtype=int)),\n",
    "        'n_estimators':     hp.choice('n_estimators',    np.arange(1, 50, 5))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(space):\n",
    "    model = XGBClassifier(n_estimators =space['n_estimators'], \n",
    "                          max_depth = int(space['max_depth']), \n",
    "                          learning_rate = space['learning_rate']\n",
    "                          )\n",
    "    evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "    \n",
    "    model.fit(X_train, y_train,\n",
    "            eval_set=evaluation, \n",
    "              eval_metric=\"mlogloss\",\n",
    "            early_stopping_rounds=10,\n",
    "              verbose=False)\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "    accuracy = 1 - accuracy_score(y_test, pred)\n",
    "\n",
    "    return {'loss': accuracy, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 100/100 [00:25<00:00,  3.90trial/s, best loss: 0.33125000000000004]\n",
      "{'learning_rate': 2, 'max_depth': 5, 'n_estimators': 7}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=hyperparameter_tuning,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100,\n",
    "            trials=trials)\n",
    "\n",
    "print (best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:11:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.54375"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=XGBClassifier(learning_rate=3,\n",
    "                    max_depth=2, \n",
    "                    n_estimators=22)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#model.predict(X_test)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# качество значительно снизилось по сравнению с подбором по GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.Выведите качество по метрике accuracy стэкинга (StackingClassifier) 4-х алгоритмов с базовыми параметрами градиентного бустинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6875\n",
      "Wall time: 39.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "estimators = [\n",
    "    ('GBC', GradientBoostingClassifier()),\n",
    "    ('XGB', XGBClassifier()),\n",
    "    ('CatBoost', CatBoostClassifier()),\n",
    "    ('LGBMClassifier', LGBMClassifier())\n",
    "\n",
    "]\n",
    "\n",
    "stack = StackingClassifier(estimators=estimators, cv=3, n_jobs=-1)\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "y_pred = stack.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# стэкинг позволил улучшить качество по сравнению с использованием отдельных алгоритмов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.Выведите качество по метрике accuracy стэкинга 4-х алгоритмов с оптимальными параметрами градиентного бустинга. Сравните результаты с предыдущим шагом и напишите какой вывод можно из этого сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6583333333333333\n",
      "Wall time: 23.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "estimators2 = [\n",
    "    ('GBC', GradientBoostingClassifier(\n",
    "        learning_rate=0.23,\n",
    "        max_depth=9,\n",
    "        n_estimators=46)\n",
    "    ),\n",
    "    ('XGB', XGBClassifier(\n",
    "        learning_rate=0.56,\n",
    "        max_depth=5,\n",
    "        n_estimators=31)\n",
    "    ),\n",
    "    ('CatBoost', CatBoostClassifier(\n",
    "        learning_rate=0.34,\n",
    "        max_depth=5,\n",
    "        n_estimators=26)\n",
    "    ),\n",
    "    ('LGBMClassifier', LGBMClassifier(\n",
    "        learning_rate=0.45,\n",
    "        max_depth=9,\n",
    "        n_estimators=36)\n",
    "     )\n",
    "]\n",
    "stack2 = StackingClassifier(estimators=estimators2, cv=3, n_jobs=-1)\n",
    "stack2.fit(X_train, y_train)\n",
    "y_pred2 = stack2.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# качество стэкинга \"оптимальных\" алгоритмов чуть ниже, чем алгоритмов с параметрами по умолчанию"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
